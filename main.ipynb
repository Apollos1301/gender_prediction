{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly as py\n",
    "import plotly.graph_objs as go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "from torchvision.models import googlenet, GoogLeNet_Weights, mobilenet_v3_small, MobileNet_V3_Small_Weights\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device) \n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize = transforms.Resize(size=(128,128))\n",
    "hFlip = transforms.RandomHorizontalFlip(p=0.25)\n",
    "vFlip = transforms.RandomVerticalFlip(p=0.25)\n",
    "rotate = transforms.RandomRotation(degrees=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([resize, hFlip, vFlip, rotate, transforms.ToTensor()])\n",
    "transform_test = transforms.Compose([resize, transforms.ToTensor()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training dataset contains 160000 samples\n",
      "[INFO] testing dataset contains 20001 samples\n",
      "[INFO] validation dataset contains 22598 samples\n"
     ]
    }
   ],
   "source": [
    "trainDataset = ImageFolder(root=\"./data/Dataset/Train\", transform=transform_train)\n",
    "testDataset = ImageFolder(root=\"./data/Dataset/Test\", transform=transform_test)\n",
    "validDataset = ImageFolder(root=\"./data/Dataset/Validation\", transform=transform_test)\n",
    "\n",
    "print(f'[INFO] training dataset contains {len(trainDataset)} samples')\n",
    "print(f'[INFO] testing dataset contains {len(testDataset)} samples')\n",
    "print(f'[INFO] validation dataset contains {len(validDataset)} samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainLoader = DataLoader(trainDataset,batch_size=BATCH_SIZE, shuffle= True)\n",
    "testLoader = DataLoader(testDataset,batch_size=BATCH_SIZE, shuffle= True)\n",
    "validLoader = DataLoader(validDataset,batch_size=BATCH_SIZE, shuffle= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_dict = {0: 'Female',\n",
    "               1: 'Male'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predefine testing method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, dataLoader):\n",
    "    model.eval()\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    count = 0\n",
    "    with torch.no_grad():\n",
    "        for X, label in dataLoader:\n",
    "            count += 1\n",
    "            if(count > 40):\n",
    "                break\n",
    "            X = X.to(device=device)\n",
    "            label = label.to(device=device)\n",
    "            label = label.reshape(-1,1).float()\n",
    "        \n",
    "            odds = model(X).float()\n",
    "            \n",
    "            predicted = odds.round()\n",
    "\n",
    "            total += label.size(0)\n",
    "            correct += (predicted == label).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GenderClassification(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GenderClassification, self).__init__()\n",
    "        self.network = nn.Sequential(\n",
    "            \n",
    "            nn.Conv2d(3, 32, kernel_size = 5, stride=3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(32,64, kernel_size = 5, stride = 3, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(64, 128, kernel_size = 3, stride = 1, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.MaxPool2d(2,2),\n",
    "            \n",
    "            nn.Flatten(),\n",
    "            nn.Linear(128,64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 12),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(12,1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        return self.network(xb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\anaconda3\\envs\\gender_prediction\\Lib\\site-packages\\torch\\optim\\lr_scheduler.py:28: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\"The verbose parameter is deprecated. Please use get_last_lr() \"\n"
     ]
    }
   ],
   "source": [
    "model = GenderClassification().to(device=device)\n",
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 1/50, loss values: 0.01824304951429367\n",
      "--- Accuracy of the model on the test data: 83.44% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 2/50, loss values: 0.012882429349422455\n",
      "--- Accuracy of the model on the test data: 88.91% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 3/50, loss values: 0.010292538130283356\n",
      "--- Accuracy of the model on the test data: 91.56% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 4/50, loss values: 0.009899481999874116\n",
      "--- Accuracy of the model on the test data: 90.00% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 5/50, loss values: 0.008639018890261651\n",
      "--- Accuracy of the model on the test data: 86.37% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 6/50, loss values: 0.00786779597401619\n",
      "--- Accuracy of the model on the test data: 89.38% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 7/50, loss values: 0.007856278586387634\n",
      "--- Accuracy of the model on the test data: 93.28% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 8/50, loss values: 0.007634099552035332\n",
      "--- Accuracy of the model on the test data: 90.43% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 9/50, loss values: 0.007271625089645386\n",
      "--- Accuracy of the model on the test data: 93.09% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 10/50, loss values: 0.0075765995293855665\n",
      "--- Accuracy of the model on the test data: 92.62% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 11/50, loss values: 0.007221623694896698\n",
      "--- Accuracy of the model on the test data: 92.58% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 12/50, loss values: 0.006482725587487221\n",
      "--- Accuracy of the model on the test data: 93.63% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 13/50, loss values: 0.006171107122302055\n",
      "--- Accuracy of the model on the test data: 93.55% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 14/50, loss values: 0.006006616136431694\n",
      "--- Accuracy of the model on the test data: 94.49% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 15/50, loss values: 0.005725603705644608\n",
      "--- Accuracy of the model on the test data: 94.06% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 16/50, loss values: 0.005439454737305641\n",
      "--- Accuracy of the model on the test data: 93.71% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 17/50, loss values: 0.005813687714934349\n",
      "--- Accuracy of the model on the test data: 94.22% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 18/50, loss values: 0.005555754068493843\n",
      "--- Accuracy of the model on the test data: 94.80% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 19/50, loss values: 0.00581564062833786\n",
      "--- Accuracy of the model on the test data: 94.41% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 20/50, loss values: 0.0058074205100536345\n",
      "--- Accuracy of the model on the test data: 94.65% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 21/50, loss values: 0.005672833856940269\n",
      "--- Accuracy of the model on the test data: 94.84% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 22/50, loss values: 0.005486501923203468\n",
      "--- Accuracy of the model on the test data: 94.45% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 23/50, loss values: 0.005711190721392632\n",
      "--- Accuracy of the model on the test data: 95.00% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 24/50, loss values: 0.005754591733217239\n",
      "--- Accuracy of the model on the test data: 94.84% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 25/50, loss values: 0.005566691699624061\n",
      "--- Accuracy of the model on the test data: 94.14% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 26/50, loss values: 0.005398686592280865\n",
      "--- Accuracy of the model on the test data: 94.84% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 27/50, loss values: 0.005232679581642151\n",
      "--- Accuracy of the model on the test data: 94.77% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 28/50, loss values: 0.005077981457114219\n",
      "--- Accuracy of the model on the test data: 94.92% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 29/50, loss values: 0.005267412906885147\n",
      "--- Accuracy of the model on the test data: 94.49% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 30/50, loss values: 0.005142709851264954\n",
      "--- Accuracy of the model on the test data: 94.88% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 31/50, loss values: 0.005527009773254395\n",
      "--- Accuracy of the model on the test data: 94.77% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 32/50, loss values: 0.005323354157805443\n",
      "--- Accuracy of the model on the test data: 95.04% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 33/50, loss values: 0.0054538357123732565\n",
      "--- Accuracy of the model on the test data: 95.35% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 34/50, loss values: 0.005046748171746731\n",
      "--- Accuracy of the model on the test data: 94.73% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 35/50, loss values: 0.0052128283947706225\n",
      "--- Accuracy of the model on the test data: 95.16% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 36/50, loss values: 0.00518607299476862\n",
      "--- Accuracy of the model on the test data: 94.88% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 37/50, loss values: 0.00502379571646452\n",
      "--- Accuracy of the model on the test data: 94.49% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 38/50, loss values: 0.005135386417806149\n",
      "--- Accuracy of the model on the test data: 95.20% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 39/50, loss values: 0.004834591978788376\n",
      "--- Accuracy of the model on the test data: 94.34% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 40/50, loss values: 0.005076401227712631\n",
      "--- Accuracy of the model on the test data: 94.96% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 41/50, loss values: 0.005285885816812515\n",
      "--- Accuracy of the model on the test data: 95.08% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 42/50, loss values: 0.005145569255948067\n",
      "--- Accuracy of the model on the test data: 95.27% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 43/50, loss values: 0.005275324043631554\n",
      "--- Accuracy of the model on the test data: 95.00% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 44/50, loss values: 0.005421464797854423\n",
      "--- Accuracy of the model on the test data: 94.77% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 45/50, loss values: 0.005032603496313095\n",
      "--- Accuracy of the model on the test data: 94.61% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 46/50, loss values: 0.005596736344695092\n",
      "--- Accuracy of the model on the test data: 95.70% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 47/50, loss values: 0.0050841179251670835\n",
      "--- Accuracy of the model on the test data: 94.73% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 48/50, loss values: 0.005380451983213424\n",
      "--- Accuracy of the model on the test data: 94.69% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 49/50, loss values: 0.004890912349522113\n",
      "--- Accuracy of the model on the test data: 94.69% ---\n",
      "processed data: 2048/5120\n",
      "processed data: 4096/5120\n",
      "Epoch: 50/50, loss values: 0.005088539186120033\n",
      "--- Accuracy of the model on the test data: 95.16% ---\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values = []\n",
    "best_accuracy = -1\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    proc_data = 0\n",
    "    for i in [0,1]:\n",
    "        if i == 0:\n",
    "            count = 0\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for X, label in trainLoader:\n",
    "                count += 1\n",
    "                if count > 80:\n",
    "                    break\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                X = X.to(device=device)\n",
    "                label = label.to(device=device)\n",
    "                label = label.reshape(-1,1).float()\n",
    "\n",
    "                odds = model(X).float()\n",
    "                loss = loss_fn(odds, label)\n",
    "\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "                proc_data += len(X)\n",
    "                if (proc_data % 2048) == 0:\n",
    "                    print(f'processed data: {proc_data}/{80 * BATCH_SIZE}')\n",
    "\n",
    "                total_loss += loss.item()\n",
    "\n",
    "\n",
    "\n",
    "            avg_loss = total_loss / len(trainLoader)\n",
    "            loss_values.append(avg_loss)\n",
    "            print(f'Epoch: {epoch+1}/{NUM_EPOCH}, loss values: {avg_loss}')\n",
    "        else:\n",
    "            accuracy = test_model(model, testLoader)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_accuracy = accuracy\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            lr_scheduler.step(accuracy)\n",
    "\n",
    "            print(f'--- Accuracy of the model on the test data: {accuracy:.2f}% ---')\n",
    "\n",
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the gender is: Female\n"
     ]
    }
   ],
   "source": [
    "# img_1 = Image.open(\"./photos/...\")\n",
    "# img_2 = Image.open(\"./photos/...\")\n",
    "\n",
    "# img_1 = transform_test(img_1).to(device)\n",
    "# img_2 = transform_test(img_2).to(device)\n",
    "\n",
    "# img_1 = torch.unsqueeze(img_1, 0)\n",
    "# img_2 = torch.unsqueeze(img_2, 0)\n",
    "\n",
    "# model.eval()\n",
    "# with torch.no_grad():\n",
    "#     output = model(img_2)\n",
    "#     gender = gender_dict[output.item() >= 0.5]\n",
    "#     print(f'the gender is: {gender}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weights = GoogLeNet_Weights.IMAGENET1K_V1\n",
    "# model = googlenet(weights=weights).to(device=device)\n",
    "\n",
    "weights = MobileNet_V3_Small_Weights.IMAGENET1K_V1\n",
    "model = mobilenet_v3_small(weights=weights).to(device=device)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=False\n",
    "\n",
    "# model.fc = nn.Linear(in_features=model.fc.in_features, out_features=1, bias=True)\n",
    "model.classifier[3] = nn.Linear(in_features=model.classifier[3].in_features, out_features=1, bias=True).to(device=device)\n",
    "activation = nn.Sigmoid().to(device=device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.classifier[3].parameters(), lr=1e-3)\n",
    "# lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "    for X, label in trainLoader:\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        X = X.to(device=device)\n",
    "        label = label.to(device=device)\n",
    "        label = label.reshape(-1,1).float()\n",
    "        \n",
    "        logits = model(X)\n",
    "        odds = activation(logits).float()\n",
    "        loss = loss_fn(odds, label)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        total_loss += loss.item()\n",
    "        \n",
    "    avg_loss = total_loss / len(trainLoader)\n",
    "    loss_values.append(avg_loss)\n",
    "    print(f'Epoch: {epoch+1}/{NUM_EPOCH}, loss values: {avg_loss}')\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = copy.deepcopy(model.state_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-2)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(best_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_accuracy = -1\n",
    "for epoch in range(NUM_EPOCH):\n",
    "    for i in [0,1]:\n",
    "        if i == 0:\n",
    "            total_loss = 0\n",
    "            model.train()\n",
    "            for X, label in trainLoader:\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                X = X.to(device=device)\n",
    "                label = label.to(device=device)\n",
    "                label = label.reshape(-1,1).float()\n",
    "                \n",
    "                logits = model(X)\n",
    "                odds = activation(logits).float()\n",
    "                loss = loss_fn(odds, label)\n",
    "                \n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            \n",
    "                total_loss += loss.item()\n",
    "                \n",
    "                \n",
    "                \n",
    "            avg_loss = total_loss / len(trainLoader)\n",
    "            loss_values.append(avg_loss)\n",
    "            print(f'Epoch: {epoch+1}/{NUM_EPOCH}, loss values: {avg_loss}')\n",
    "        else:\n",
    "            accuracy = test_model(model, testLoader)\n",
    "            if accuracy > best_accuracy:\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "            lr_scheduler.step(accuracy)\n",
    "            \n",
    "            print(f'--- Accuracy of the model on the test data: {accuracy:.2f}% ---')\n",
    "            \n",
    "model.load_state_dict(best_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gender_prediction",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
